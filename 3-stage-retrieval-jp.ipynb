{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Retrieval with Multi-Stage Re-Ranking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # Check the CUDA version\n",
    "print(torch.cuda.is_available())  # Check if CUDA is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "\n",
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "510\n",
      "508\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)\n",
    "print(tokenizer.max_len_single_sentence)\n",
    "print(tokenizer.max_len_sentences_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenizer.encode(text, max_length=500, truncation=True, padding=\"max_length\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 6.4447e+01,  3.2508e-02,  3.7382e+01,  ...,  2.1459e+01,\n",
       "           1.4222e+01,  1.8874e+01],\n",
       "         [ 2.7079e+01, -1.3935e+00,  6.4573e+01,  ...,  4.0109e+01,\n",
       "           1.6137e+01,  3.1009e+01],\n",
       "         [ 1.9189e+01, -1.2440e+00,  4.8706e+01,  ...,  3.5705e+01,\n",
       "           1.6987e+01,  2.7256e+01],\n",
       "         ...,\n",
       "         [ 2.2506e+01, -1.4501e+00,  5.0936e+01,  ...,  3.8371e+01,\n",
       "           1.6350e+01,  2.7771e+01],\n",
       "         [ 2.8184e+01, -1.2711e+00,  6.7431e+01,  ...,  4.4732e+01,\n",
       "           1.7845e+01,  3.5088e+01],\n",
       "         [ 4.4540e+01, -1.9992e-01,  4.9368e+01,  ...,  2.8129e+01,\n",
       "           1.6683e+01,  2.3694e+01]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/legal_corpus_update.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    legal_corpus = json.load(f)\n",
    "\n",
    "new_legal_corpus = []\n",
    "id = 0\n",
    "for laws in legal_corpus:\n",
    "    for article in laws[\"articles\"]:\n",
    "        new_legal_corpus.append({\n",
    "            \"_id\": \"corpus_\"+str(id),\n",
    "            \"law_id\": laws[\"law_id\"],\n",
    "            \"article_id\": article[\"article_id\"],\n",
    "            \"title\": article[\"title\"],\n",
    "            \"text\": article[\"text\"]\n",
    "        })\n",
    "        id+=1\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/corpus.jsonl\", \"w\") as f:\n",
    "    for law in new_legal_corpus:\n",
    "        json_line = json.dumps(law, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'corpus_0',\n",
       " 'law_id': '賃金の支払の確保等に関する法律/第一章\\u3000総則',\n",
       " 'article_id': '1',\n",
       " 'title': '第一条\\u3000目的',\n",
       " 'text': 'この法律は、景気の変動、産業構造の変化その他の事情により企業経営が安定を欠くに至つた場合及び労働者が事業を退職する場合における賃金の支払等の適正化を図るため、貯蓄金の保全措置及び事業活動に著しい支障を生じたことにより賃金の支払を受けることが困難となつた労働者に対する保護措置その他賃金の支払の確保に関する措置を講じ、もつて労働者の生活の安定に資することを目的とする。'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_legal_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/train_12x7_retrieval.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/validation_12x7_retrieval.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/test_12x7_retrieval.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "queries = []\n",
    "id = 0\n",
    "for question in train_data[\"items\"]+dev_data[\"items\"]+test_data[\"items\"]:\n",
    "    queries.append({\n",
    "        \"_id\": \"query_\"+str(id),\n",
    "        \"text\": question[\"question_full\"],\n",
    "        \"relevant_articles\": question[\"relevant_articles\"]\n",
    "    })\n",
    "    id+=1\n",
    "\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/queries.jsonl\", \"w\") as f:\n",
    "    for question in queries:\n",
    "        json_line = json.dumps(question, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'query_0',\n",
       " 'text': '第１章\\u3000総則\\n（規則の遵守）\\n第３条\\u3000会社と社員は、ともに本規則を遵守し、相互に協力して社業の発展に努めなければならない。',\n",
       " 'relevant_articles': [{'law_id': '労働基準法/第一章\\u3000総則', 'article_id': '2'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs('/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/qrels', exist_ok=True)\n",
    "train = {\"query-id\": [], \"corpus-id\": [], \"score\":[]}\n",
    "dev = {\"query-id\": [], \"corpus-id\": [], \"score\":[]}\n",
    "test = {\"query-id\": [], \"corpus-id\": [], \"score\":[]}\n",
    "\n",
    "id = 0\n",
    "for question in train_data[\"items\"]:\n",
    "    for law in question[\"relevant_articles\"]:\n",
    "        for corpus in new_legal_corpus:\n",
    "            if law['law_id'] == corpus['law_id'] and law['article_id'] == corpus['article_id']:\n",
    "                train[\"query-id\"].append(\"query_\"+str(id))\n",
    "                train[\"corpus-id\"].append(corpus[\"_id\"])\n",
    "                train[\"score\"].append(1)\n",
    "                break\n",
    "    id+=1\n",
    "train_df = pd.DataFrame(train)\n",
    "train_df.to_csv(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/qrels/train.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "for question in dev_data[\"items\"]:\n",
    "    for law in question[\"relevant_articles\"]:\n",
    "        for corpus in new_legal_corpus:\n",
    "            if law['law_id'] == corpus['law_id'] and law['article_id'] == corpus['article_id']:\n",
    "                dev[\"query-id\"].append(\"query_\"+str(id))\n",
    "                dev[\"corpus-id\"].append(corpus[\"_id\"])\n",
    "                dev[\"score\"].append(1)\n",
    "                break\n",
    "    id+=1\n",
    "dev_df = pd.DataFrame(dev)\n",
    "dev_df.to_csv(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/qrels/dev.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "for question in test_data[\"items\"]:\n",
    "    for law in question[\"relevant_articles\"]:\n",
    "        for corpus in new_legal_corpus:\n",
    "            if law['law_id'] == corpus['law_id'] and law['article_id'] == corpus['article_id']:\n",
    "                test[\"query-id\"].append(\"query_\"+str(id))\n",
    "                test[\"corpus-id\"].append(corpus[\"_id\"])\n",
    "                test[\"score\"].append(1)\n",
    "                break\n",
    "    id+=1\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df.to_csv(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/qrels/test.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus in new_legal_corpus:\n",
    "    corpus[\"text\"] = corpus[\"law_id\"] + \"\\n\" + corpus[\"title\"] + \"\\n\" + corpus[\"text\"]\n",
    "    del corpus[\"law_id\"]\n",
    "    del corpus[\"title\"]\n",
    "    del corpus[\"article_id\"]\n",
    "\n",
    "with open(\"/home/hoang/multi-stage-reranking/dataset/beir/original/12_7/corpus.jsonl\", \"w\") as f:\n",
    "    for law in new_legal_corpus:\n",
    "        json_line = json.dumps(law, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47M\t/home/hoang/multi-stage-reranking/dataset/beir/original/fiqa\n",
      "8.0M\t/home/hoang/multi-stage-reranking/dataset/beir/original/scifact\n",
      "3.4G\t/home/hoang/multi-stage-reranking/dataset/beir/original/msmarco\n",
      "2.1G\t/home/hoang/multi-stage-reranking/dataset/beir/original/hotpotqa\n",
      "6.7M\t/home/hoang/multi-stage-reranking/dataset/beir/original/12_7\n",
      "5.5G\t/home/hoang/multi-stage-reranking/dataset/beir/original\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 1 /home/hoang/multi-stage-reranking/dataset/beir/original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T08:53:44.306042Z",
     "iopub.status.busy": "2024-10-08T08:53:44.305224Z",
     "iopub.status.idle": "2024-10-08T09:22:13.658843Z",
     "shell.execute_reply": "2024-10-08T09:22:13.657288Z",
     "shell.execute_reply.started": "2024-10-08T08:53:44.306003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/743 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 743/743 [00:00<00:00, 2552.17it/s]\n",
      "100%|██████████| 3462/3462 [00:00<00:00, 7770.78it/s]\n",
      "3459it [00:00, 272713.73it/s]\n",
      "101it [00:00, 1173475.63it/s]\n",
      "292it [00:00, 1574211.78it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/hoang/multi-stage-reranking\n",
    "python preprocess_beir.py \\\n",
    "--data_path dataset/beir/original/12_7 \\\n",
    "--output_data_path dataset/beir/processed/12_7 \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157M\t/home/hoang/multi-stage-reranking/dataset/beir/processed/fiqa\n",
      "20M\t/home/hoang/multi-stage-reranking/dataset/beir/processed/scifact\n",
      "18G\t/home/hoang/multi-stage-reranking/dataset/beir/processed/msmarco\n",
      "9.9G\t/home/hoang/multi-stage-reranking/dataset/beir/processed/hotpotqa\n",
      "8.5M\t/home/hoang/multi-stage-reranking/dataset/beir/processed/12_7\n",
      "28G\t/home/hoang/multi-stage-reranking/dataset/beir/processed\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 1 /home/hoang/multi-stage-reranking/dataset/beir/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyserini==0.19.2 numpy==1.26.1 faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2024-10-31 03:46:20,817 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Setting log level to INFO\n",
      "2024-10-31 03:46:20,818 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Starting indexer...\n",
      "2024-10-31 03:46:20,818 INFO  [main] index.IndexCollection (IndexCollection.java:395) - ============ Loading Parameters ============\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:396) - DocumentCollection path: dataset/beir/processed_bm25/12_7/document_processed\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:397) - CollectionClass: JsonCollection\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Generator: DefaultLuceneDocumentGenerator\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Threads: 1\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Language: en\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Stemmer: porter\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:402) - Keep stopwords? false\n",
      "2024-10-31 03:46:20,819 INFO  [main] index.IndexCollection (IndexCollection.java:403) - Stopwords: null\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:404) - Store positions? false\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:405) - Store docvectors? false\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:406) - Store document \"contents\" field? false\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:407) - Store document \"raw\" field? false\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:408) - Additional fields to index: []\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:409) - Optimize (merge segments)? false\n",
      "2024-10-31 03:46:20,820 INFO  [main] index.IndexCollection (IndexCollection.java:410) - Whitelist: null\n",
      "2024-10-31 03:46:20,821 INFO  [main] index.IndexCollection (IndexCollection.java:411) - Pretokenized?: false\n",
      "2024-10-31 03:46:20,821 INFO  [main] index.IndexCollection (IndexCollection.java:412) - Index path: dataset/beir/processed_bm25/12_7/index\n",
      "2024-10-31 03:46:20,822 INFO  [main] index.IndexCollection (IndexCollection.java:450) - ============ Indexing Collection ============\n",
      "2024-10-31 03:46:21,129 INFO  [main] index.IndexCollection (IndexCollection.java:565) - Thread pool with 1 threads initialized.\n",
      "2024-10-31 03:46:21,129 INFO  [main] index.IndexCollection (IndexCollection.java:567) - Initializing collection in dataset/beir/processed_bm25/12_7/document_processed\n",
      "2024-10-31 03:46:21,131 INFO  [main] index.IndexCollection (IndexCollection.java:576) - 1 file found\n",
      "2024-10-31 03:46:21,131 INFO  [main] index.IndexCollection (IndexCollection.java:577) - Starting to index...\n",
      "2024-10-31 03:46:21,457 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:356) - document_processed/document_processed.json: 743 docs added.\n",
      "2024-10-31 03:46:21,673 INFO  [main] index.IndexCollection (IndexCollection.java:633) - Indexing Complete! 743 documents indexed\n",
      "2024-10-31 03:46:21,673 INFO  [main] index.IndexCollection (IndexCollection.java:634) - ============ Final Counter Values ============\n",
      "2024-10-31 03:46:21,673 INFO  [main] index.IndexCollection (IndexCollection.java:635) - indexed:              743\n",
      "2024-10-31 03:46:21,674 INFO  [main] index.IndexCollection (IndexCollection.java:636) - unindexable:            0\n",
      "2024-10-31 03:46:21,674 INFO  [main] index.IndexCollection (IndexCollection.java:637) - empty:                  0\n",
      "2024-10-31 03:46:21,674 INFO  [main] index.IndexCollection (IndexCollection.java:638) - skipped:                0\n",
      "2024-10-31 03:46:21,674 INFO  [main] index.IndexCollection (IndexCollection.java:639) - errors:                 0\n",
      "2024-10-31 03:46:21,705 INFO  [main] index.IndexCollection (IndexCollection.java:642) - Total 743 documents indexed in 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3259/3259 [00:14<00:00, 224.30it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 266.22it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 216.33it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/hoang/multi-stage-reranking\n",
    "python preprocess_bm25.py \\\n",
    "--data_path dataset/beir/processed/12_7 \\\n",
    "--output_data_path dataset/beir/processed_bm25/12_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58M\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25/fiqa\n",
      "9.6M\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25/scifact\n",
      "4.3G\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25/msmarco\n",
      "2.0G\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25/hotpotqa\n",
      "9.9M\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25/12_7\n",
      "6.3G\t/home/hoang/multi-stage-reranking/dataset/beir/processed_bm25\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 1 /home/hoang/multi-stage-reranking/dataset/beir/processed_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal (pointwise) LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 03:55:23 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 03:55:23 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/dev.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0', do_train=True, do_eval=False, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=0, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='FacebookAI/xlm-roberta-base', config_name=None, tokenizer_name_or_path='FacebookAI/xlm-roberta-base', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "FacebookAI/xlm-roberta-base\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "10/31/2024 03:55:27 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 03:55:27 - INFO - __main__ -   train_dataset_size: 6518, eval_dataset_size: 365\n",
      "10/31/2024 03:55:27 - INFO - __main__ -   total steps: 1020, warmup_steps: 62\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 03:55:28 - INFO - __main__ -   *** Train ***\n",
      "  0%|                                                  | 0/1020 [00:00<?, ?it/s]10/31/2024 03:55:28 - INFO - __main__ -   start epoch 0\n",
      " 10%|████                                    | 102/1020 [01:05<09:06,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.65it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.26it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.68it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 21.03it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.08it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 21.03it/s]\u001b[A\n",
      "preds: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 03:56:34 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 03:56:34 - INFO - __main__ -     accuracy = 0.8383561643835616\n",
      "10/31/2024 03:56:34 - INFO - __main__ -     f1 = 0.6424242424242425\n",
      "10/31/2024 03:56:34 - INFO - __main__ -     loss = 0.38001436804947647\n",
      "10/31/2024 03:56:34 - INFO - __main__ -     precision = 0.5760869565217391\n",
      "10/31/2024 03:56:34 - INFO - __main__ -     recall = 0.726027397260274\n",
      "10/31/2024 03:56:34 - INFO - __main__ -   start epoch 1\n",
      " 20%|████████                                | 204/1020 [02:10<08:05,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.64it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.86it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.41it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.71it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.84it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.87it/s]\u001b[A\n",
      "preds: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 03:57:39 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 03:57:39 - INFO - __main__ -     accuracy = 0.873972602739726\n",
      "10/31/2024 03:57:39 - INFO - __main__ -     f1 = 0.7088607594936709\n",
      "10/31/2024 03:57:39 - INFO - __main__ -     loss = 0.3520933903105881\n",
      "10/31/2024 03:57:39 - INFO - __main__ -     precision = 0.6588235294117647\n",
      "10/31/2024 03:57:39 - INFO - __main__ -     recall = 0.7671232876712328\n",
      "10/31/2024 03:57:39 - INFO - __main__ -   start epoch 2\n",
      " 30%|████████████                            | 306/1020 [03:15<07:07,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.49it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.25it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.61it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.82it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.93it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.96it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 03:58:45 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 03:58:45 - INFO - __main__ -     accuracy = 0.8794520547945206\n",
      "10/31/2024 03:58:45 - INFO - __main__ -     f1 = 0.6666666666666666\n",
      "10/31/2024 03:58:45 - INFO - __main__ -     loss = 0.31684981578070187\n",
      "10/31/2024 03:58:45 - INFO - __main__ -     precision = 0.7457627118644068\n",
      "10/31/2024 03:58:45 - INFO - __main__ -     recall = 0.6027397260273972\n",
      "10/31/2024 03:58:45 - INFO - __main__ -   start epoch 3\n",
      " 40%|████████████████                        | 408/1020 [04:21<06:08,  1.66it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.35it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.18it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.58it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.81it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.94it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 03:59:50 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 03:59:50 - INFO - __main__ -     accuracy = 0.8712328767123287\n",
      "10/31/2024 03:59:50 - INFO - __main__ -     f1 = 0.6713286713286714\n",
      "10/31/2024 03:59:50 - INFO - __main__ -     loss = 0.3203233143557673\n",
      "10/31/2024 03:59:50 - INFO - __main__ -     precision = 0.6857142857142857\n",
      "10/31/2024 03:59:50 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 03:59:50 - INFO - __main__ -   start epoch 4\n",
      " 50%|████████████████████                    | 510/1020 [05:26<05:05,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.66it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.26it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.64it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.81it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.92it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.99it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.96it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:00:55 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:00:55 - INFO - __main__ -     accuracy = 0.8958904109589041\n",
      "10/31/2024 04:00:55 - INFO - __main__ -     f1 = 0.7076923076923077\n",
      "10/31/2024 04:00:55 - INFO - __main__ -     loss = 0.46600916657758795\n",
      "10/31/2024 04:00:55 - INFO - __main__ -     precision = 0.8070175438596491\n",
      "10/31/2024 04:00:55 - INFO - __main__ -     recall = 0.6301369863013698\n",
      "10/31/2024 04:00:55 - INFO - __main__ -   start epoch 5\n",
      " 60%|████████████████████████                | 612/1020 [06:31<04:04,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.29it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.12it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.54it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.79it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.93it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:02:01 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:02:01 - INFO - __main__ -     accuracy = 0.8904109589041096\n",
      "10/31/2024 04:02:01 - INFO - __main__ -     f1 = 0.7222222222222222\n",
      "10/31/2024 04:02:01 - INFO - __main__ -     loss = 0.31472677478323813\n",
      "10/31/2024 04:02:01 - INFO - __main__ -     precision = 0.7323943661971831\n",
      "10/31/2024 04:02:01 - INFO - __main__ -     recall = 0.7123287671232876\n",
      "10/31/2024 04:02:01 - INFO - __main__ -   start epoch 6\n",
      " 70%|████████████████████████████            | 714/1020 [07:37<03:03,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.73it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.30it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.65it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.86it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.92it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.02it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.98it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:03:06 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:03:06 - INFO - __main__ -     accuracy = 0.9013698630136986\n",
      "10/31/2024 04:03:06 - INFO - __main__ -     f1 = 0.7464788732394366\n",
      "10/31/2024 04:03:06 - INFO - __main__ -     loss = 0.3092704851018346\n",
      "10/31/2024 04:03:06 - INFO - __main__ -     precision = 0.7681159420289855\n",
      "10/31/2024 04:03:06 - INFO - __main__ -     recall = 0.726027397260274\n",
      "10/31/2024 04:03:06 - INFO - __main__ -   start epoch 7\n",
      " 80%|████████████████████████████████        | 816/1020 [08:42<02:02,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.79it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.82it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.32it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.62it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.75it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.84it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.79it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:04:12 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:04:12 - INFO - __main__ -     accuracy = 0.8958904109589041\n",
      "10/31/2024 04:04:12 - INFO - __main__ -     f1 = 0.7205882352941176\n",
      "10/31/2024 04:04:12 - INFO - __main__ -     loss = 0.3581302781467852\n",
      "10/31/2024 04:04:12 - INFO - __main__ -     precision = 0.7777777777777778\n",
      "10/31/2024 04:04:12 - INFO - __main__ -     recall = 0.6712328767123288\n",
      "10/31/2024 04:04:12 - INFO - __main__ -   start epoch 8\n",
      " 90%|████████████████████████████████████    | 918/1020 [09:48<01:01,  1.66it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.33it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.14it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.57it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.80it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.90it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.97it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.02it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.95it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:05:17 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:05:17 - INFO - __main__ -     accuracy = 0.8931506849315068\n",
      "10/31/2024 04:05:17 - INFO - __main__ -     f1 = 0.7310344827586207\n",
      "10/31/2024 04:05:17 - INFO - __main__ -     loss = 0.35588782539834146\n",
      "10/31/2024 04:05:17 - INFO - __main__ -     precision = 0.7361111111111112\n",
      "10/31/2024 04:05:17 - INFO - __main__ -     recall = 0.726027397260274\n",
      "10/31/2024 04:05:17 - INFO - __main__ -   start epoch 9\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:53<00:00,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.98it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.97it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.44it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.70it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.83it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.98it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.87it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:06:23 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:06:23 - INFO - __main__ -     accuracy = 0.8958904109589041\n",
      "10/31/2024 04:06:23 - INFO - __main__ -     f1 = 0.7246376811594203\n",
      "10/31/2024 04:06:23 - INFO - __main__ -     loss = 0.37258235640499904\n",
      "10/31/2024 04:06:23 - INFO - __main__ -     precision = 0.7692307692307693\n",
      "10/31/2024 04:06:23 - INFO - __main__ -     recall = 0.684931506849315\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:54<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--tokenizer_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--do_train \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 0 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 06:38:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 06:38:39 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/dev.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0', do_train=False, do_eval=False, do_test=True, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=0, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0', config_name=None, tokenizer_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0\n",
      "10/31/2024 06:38:47 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 06:38:47 - INFO - __main__ -   train_dataset_size: 0, eval_dataset_size: 365\n",
      "10/31/2024 06:38:47 - INFO - __main__ -   total steps: 0, warmup_steps: 0\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 06:38:48 - INFO - __main__ -   *** Test ***\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 18.82it/s]\n",
      "preds: [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 06:38:49 - INFO - __main__ -   ***** Test results *****\n",
      "10/31/2024 06:38:49 - INFO - __main__ -     accuracy = 0.9123287671232877\n",
      "10/31/2024 06:38:49 - INFO - __main__ -     f1 = 0.7647058823529411\n",
      "10/31/2024 06:38:49 - INFO - __main__ -     loss = 0.3437819530903969\n",
      "10/31/2024 06:38:49 - INFO - __main__ -     precision = 0.8253968253968254\n",
      "10/31/2024 06:38:49 - INFO - __main__ -     recall = 0.7123287671232876\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "--tokenizer_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "--do_test \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 0 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 04:11:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 04:11:38 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/dev.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1', do_train=True, do_eval=False, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=1, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='FacebookAI/xlm-roberta-base', config_name=None, tokenizer_name_or_path='FacebookAI/xlm-roberta-base', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "FacebookAI/xlm-roberta-base\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "10/31/2024 04:11:41 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 04:11:42 - INFO - __main__ -   train_dataset_size: 6518, eval_dataset_size: 365\n",
      "10/31/2024 04:11:42 - INFO - __main__ -   total steps: 1020, warmup_steps: 62\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 04:11:42 - INFO - __main__ -   *** Train ***\n",
      "  0%|                                                  | 0/1020 [00:00<?, ?it/s]10/31/2024 04:11:42 - INFO - __main__ -   start epoch 0\n",
      " 10%|████                                    | 102/1020 [01:05<09:13,  1.66it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.12it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.09it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.61it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.82it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.85it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.98it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.92it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:12:49 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:12:49 - INFO - __main__ -     accuracy = 0.8684931506849315\n",
      "10/31/2024 04:12:49 - INFO - __main__ -     f1 = 0.52\n",
      "10/31/2024 04:12:49 - INFO - __main__ -     loss = 0.3981965853144293\n",
      "10/31/2024 04:12:49 - INFO - __main__ -     precision = 0.9629629629629629\n",
      "10/31/2024 04:12:49 - INFO - __main__ -     recall = 0.3561643835616438\n",
      "10/31/2024 04:12:49 - INFO - __main__ -   start epoch 1\n",
      " 20%|████████                                | 204/1020 [02:10<08:11,  1.66it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.52it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.18it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.58it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.73it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.81it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.88it/s]\u001b[A\n",
      "preds: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:13:54 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:13:54 - INFO - __main__ -     accuracy = 0.9041095890410958\n",
      "10/31/2024 04:13:54 - INFO - __main__ -     f1 = 0.7107438016528925\n",
      "10/31/2024 04:13:54 - INFO - __main__ -     loss = 0.38483884768641513\n",
      "10/31/2024 04:13:54 - INFO - __main__ -     precision = 0.8958333333333334\n",
      "10/31/2024 04:13:54 - INFO - __main__ -     recall = 0.589041095890411\n",
      "10/31/2024 04:13:54 - INFO - __main__ -   start epoch 2\n",
      " 30%|████████████                            | 306/1020 [03:15<07:04,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.80it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.90it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.47it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.73it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.81it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.88it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.85it/s]\u001b[A\n",
      "preds: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:14:59 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:14:59 - INFO - __main__ -     accuracy = 0.9013698630136986\n",
      "10/31/2024 04:14:59 - INFO - __main__ -     f1 = 0.7230769230769231\n",
      "10/31/2024 04:14:59 - INFO - __main__ -     loss = 0.3760442350707624\n",
      "10/31/2024 04:14:59 - INFO - __main__ -     precision = 0.8245614035087719\n",
      "10/31/2024 04:14:59 - INFO - __main__ -     recall = 0.6438356164383562\n",
      "10/31/2024 04:14:59 - INFO - __main__ -   start epoch 3\n",
      " 40%|████████████████                        | 408/1020 [04:21<06:02,  1.69it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.39it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.16it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.59it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.83it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.94it/s]\u001b[A\n",
      "preds: [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:16:05 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:16:05 - INFO - __main__ -     accuracy = 0.9013698630136986\n",
      "10/31/2024 04:16:05 - INFO - __main__ -     f1 = 0.7272727272727273\n",
      "10/31/2024 04:16:05 - INFO - __main__ -     loss = 0.299289480175661\n",
      "10/31/2024 04:16:05 - INFO - __main__ -     precision = 0.8135593220338984\n",
      "10/31/2024 04:16:05 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:16:05 - INFO - __main__ -   start epoch 4\n",
      " 50%|████████████████████                    | 510/1020 [05:26<05:04,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.82it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.93it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.49it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.72it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.84it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.92it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.84it/s]\u001b[A\n",
      "preds: [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:17:10 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:17:10 - INFO - __main__ -     accuracy = 0.8904109589041096\n",
      "10/31/2024 04:17:10 - INFO - __main__ -     f1 = 0.6875\n",
      "10/31/2024 04:17:10 - INFO - __main__ -     loss = 0.37728892048091994\n",
      "10/31/2024 04:17:10 - INFO - __main__ -     precision = 0.8\n",
      "10/31/2024 04:17:10 - INFO - __main__ -     recall = 0.6027397260273972\n",
      "10/31/2024 04:17:10 - INFO - __main__ -   start epoch 5\n",
      " 60%|████████████████████████                | 612/1020 [06:32<04:03,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.39it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.12it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.56it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.75it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.85it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.92it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.88it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:18:16 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:18:16 - INFO - __main__ -     accuracy = 0.9095890410958904\n",
      "10/31/2024 04:18:16 - INFO - __main__ -     f1 = 0.7317073170731707\n",
      "10/31/2024 04:18:16 - INFO - __main__ -     loss = 0.26236305223858875\n",
      "10/31/2024 04:18:16 - INFO - __main__ -     precision = 0.9\n",
      "10/31/2024 04:18:16 - INFO - __main__ -     recall = 0.6164383561643836\n",
      "10/31/2024 04:18:16 - INFO - __main__ -   start epoch 6\n",
      " 70%|████████████████████████████            | 714/1020 [07:37<03:01,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.37it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.11it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.58it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.80it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.97it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.91it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:19:21 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:19:21 - INFO - __main__ -     accuracy = 0.9205479452054794\n",
      "10/31/2024 04:19:21 - INFO - __main__ -     f1 = 0.7603305785123967\n",
      "10/31/2024 04:19:21 - INFO - __main__ -     loss = 0.32297328972946043\n",
      "10/31/2024 04:19:21 - INFO - __main__ -     precision = 0.9583333333333334\n",
      "10/31/2024 04:19:21 - INFO - __main__ -     recall = 0.6301369863013698\n",
      "10/31/2024 04:19:21 - INFO - __main__ -   start epoch 7\n",
      " 80%|████████████████████████████████        | 816/1020 [08:42<02:00,  1.69it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.36it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.15it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.60it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.80it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.93it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.98it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.92it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:20:26 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:20:26 - INFO - __main__ -     accuracy = 0.9095890410958904\n",
      "10/31/2024 04:20:26 - INFO - __main__ -     f1 = 0.7518796992481203\n",
      "10/31/2024 04:20:26 - INFO - __main__ -     loss = 0.22408962873337063\n",
      "10/31/2024 04:20:26 - INFO - __main__ -     precision = 0.8333333333333334\n",
      "10/31/2024 04:20:26 - INFO - __main__ -     recall = 0.684931506849315\n",
      "10/31/2024 04:20:26 - INFO - __main__ -   start epoch 8\n",
      " 90%|████████████████████████████████████    | 918/1020 [09:47<01:00,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.11it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.02it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.53it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.76it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.87it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.89it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:21:31 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:21:31 - INFO - __main__ -     accuracy = 0.915068493150685\n",
      "10/31/2024 04:21:31 - INFO - __main__ -     f1 = 0.7559055118110236\n",
      "10/31/2024 04:21:31 - INFO - __main__ -     loss = 0.2874063986313084\n",
      "10/31/2024 04:21:31 - INFO - __main__ -     precision = 0.8888888888888888\n",
      "10/31/2024 04:21:31 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:21:31 - INFO - __main__ -   start epoch 9\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:52<00:00,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.05it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.01it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.53it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.76it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.86it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.88it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:22:36 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:22:36 - INFO - __main__ -     accuracy = 0.9232876712328767\n",
      "10/31/2024 04:22:36 - INFO - __main__ -     f1 = 0.78125\n",
      "10/31/2024 04:22:36 - INFO - __main__ -     loss = 0.23474843111699042\n",
      "10/31/2024 04:22:36 - INFO - __main__ -     precision = 0.9090909090909091\n",
      "10/31/2024 04:22:36 - INFO - __main__ -     recall = 0.684931506849315\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:53<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--tokenizer_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--do_train \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 1 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 06:37:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 06:37:43 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/dev.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1', do_train=False, do_eval=False, do_test=True, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=1, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1', config_name=None, tokenizer_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1\n",
      "10/31/2024 06:37:45 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 06:37:45 - INFO - __main__ -   train_dataset_size: 0, eval_dataset_size: 365\n",
      "10/31/2024 06:37:45 - INFO - __main__ -   total steps: 0, warmup_steps: 0\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 06:37:45 - INFO - __main__ -   *** Test ***\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 18.87it/s]\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 06:37:46 - INFO - __main__ -   ***** Test results *****\n",
      "10/31/2024 06:37:46 - INFO - __main__ -     accuracy = 0.9232876712328767\n",
      "10/31/2024 06:37:46 - INFO - __main__ -     f1 = 0.7910447761194029\n",
      "10/31/2024 06:37:46 - INFO - __main__ -     loss = 0.24637244410974823\n",
      "10/31/2024 06:37:46 - INFO - __main__ -     precision = 0.8688524590163934\n",
      "10/31/2024 06:37:46 - INFO - __main__ -     recall = 0.726027397260274\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--tokenizer_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--do_test \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 1 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 04:22:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 04:22:43 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/dev.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2', do_train=True, do_eval=False, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=2, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='FacebookAI/xlm-roberta-base', config_name=None, tokenizer_name_or_path='FacebookAI/xlm-roberta-base', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "FacebookAI/xlm-roberta-base\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "10/31/2024 04:22:46 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 04:22:47 - INFO - __main__ -   train_dataset_size: 6518, eval_dataset_size: 365\n",
      "10/31/2024 04:22:47 - INFO - __main__ -   total steps: 1020, warmup_steps: 62\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 04:22:47 - INFO - __main__ -   *** Train ***\n",
      "  0%|                                                  | 0/1020 [00:00<?, ?it/s]10/31/2024 04:22:47 - INFO - __main__ -   start epoch 0\n",
      " 10%|████                                    | 102/1020 [01:04<09:08,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 17.80it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.88it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.43it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.70it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.83it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.91it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.84it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:23:52 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:23:52 - INFO - __main__ -     accuracy = 0.8712328767123287\n",
      "10/31/2024 04:23:52 - INFO - __main__ -     f1 = 0.6618705035971223\n",
      "10/31/2024 04:23:52 - INFO - __main__ -     loss = 0.39011331647634506\n",
      "10/31/2024 04:23:52 - INFO - __main__ -     precision = 0.696969696969697\n",
      "10/31/2024 04:23:52 - INFO - __main__ -     recall = 0.6301369863013698\n",
      "10/31/2024 04:23:52 - INFO - __main__ -   start epoch 1\n",
      " 20%|████████                                | 204/1020 [02:10<08:51,  1.54it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 16.42it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.29it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.10it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.50it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.72it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.83it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.90it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.65it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:24:59 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:24:59 - INFO - __main__ -     accuracy = 0.8931506849315068\n",
      "10/31/2024 04:24:59 - INFO - __main__ -     f1 = 0.6829268292682927\n",
      "10/31/2024 04:24:59 - INFO - __main__ -     loss = 0.37564743261622346\n",
      "10/31/2024 04:24:59 - INFO - __main__ -     precision = 0.84\n",
      "10/31/2024 04:24:59 - INFO - __main__ -     recall = 0.5753424657534246\n",
      "10/31/2024 04:24:59 - INFO - __main__ -   start epoch 2\n",
      " 30%|████████████                            | 306/1020 [03:16<07:17,  1.63it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.86it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.33it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.69it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.86it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.96it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.98it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:26:05 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:26:05 - INFO - __main__ -     accuracy = 0.9068493150684932\n",
      "10/31/2024 04:26:05 - INFO - __main__ -     f1 = 0.7384615384615385\n",
      "10/31/2024 04:26:05 - INFO - __main__ -     loss = 0.26097944953843305\n",
      "10/31/2024 04:26:05 - INFO - __main__ -     precision = 0.8421052631578947\n",
      "10/31/2024 04:26:05 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:26:05 - INFO - __main__ -   start epoch 3\n",
      " 40%|████████████████                        | 408/1020 [04:22<06:04,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.19it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.07it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.49it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.74it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.87it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.91it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:27:11 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:27:11 - INFO - __main__ -     accuracy = 0.8931506849315068\n",
      "10/31/2024 04:27:11 - INFO - __main__ -     f1 = 0.706766917293233\n",
      "10/31/2024 04:27:11 - INFO - __main__ -     loss = 0.30368862349701964\n",
      "10/31/2024 04:27:11 - INFO - __main__ -     precision = 0.7833333333333333\n",
      "10/31/2024 04:27:11 - INFO - __main__ -     recall = 0.6438356164383562\n",
      "10/31/2024 04:27:11 - INFO - __main__ -   start epoch 4\n",
      " 50%|████████████████████                    | 510/1020 [05:28<05:05,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.16it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.07it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.54it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.78it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.90it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.98it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.88it/s]\u001b[A\n",
      "preds: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:28:17 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:28:17 - INFO - __main__ -     accuracy = 0.8684931506849315\n",
      "10/31/2024 04:28:17 - INFO - __main__ -     f1 = 0.7\n",
      "10/31/2024 04:28:17 - INFO - __main__ -     loss = 0.28600840181436227\n",
      "10/31/2024 04:28:17 - INFO - __main__ -     precision = 0.6436781609195402\n",
      "10/31/2024 04:28:17 - INFO - __main__ -     recall = 0.7671232876712328\n",
      "10/31/2024 04:28:17 - INFO - __main__ -   start epoch 5\n",
      " 60%|████████████████████████                | 612/1020 [06:34<04:02,  1.68it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.07it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.97it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.43it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.67it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.74it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.74it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.76it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.72it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:29:23 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:29:23 - INFO - __main__ -     accuracy = 0.9013698630136986\n",
      "10/31/2024 04:29:23 - INFO - __main__ -     f1 = 0.7272727272727273\n",
      "10/31/2024 04:29:23 - INFO - __main__ -     loss = 0.34093613132996403\n",
      "10/31/2024 04:29:23 - INFO - __main__ -     precision = 0.8135593220338984\n",
      "10/31/2024 04:29:23 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:29:23 - INFO - __main__ -   start epoch 6\n",
      " 70%|████████████████████████████            | 714/1020 [07:39<03:02,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.38it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.06it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.49it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.70it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.80it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.86it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.84it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:30:28 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:30:28 - INFO - __main__ -     accuracy = 0.8904109589041096\n",
      "10/31/2024 04:30:28 - INFO - __main__ -     f1 = 0.6923076923076923\n",
      "10/31/2024 04:30:28 - INFO - __main__ -     loss = 0.3202274546189153\n",
      "10/31/2024 04:30:28 - INFO - __main__ -     precision = 0.7894736842105263\n",
      "10/31/2024 04:30:28 - INFO - __main__ -     recall = 0.6164383561643836\n",
      "10/31/2024 04:30:28 - INFO - __main__ -   start epoch 7\n",
      " 80%|████████████████████████████████        | 816/1020 [08:45<02:02,  1.67it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.12it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 19.97it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.45it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.69it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.78it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.86it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 20.89it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.82it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:31:34 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:31:34 - INFO - __main__ -     accuracy = 0.8931506849315068\n",
      "10/31/2024 04:31:34 - INFO - __main__ -     f1 = 0.7111111111111111\n",
      "10/31/2024 04:31:34 - INFO - __main__ -     loss = 0.3945535548011084\n",
      "10/31/2024 04:31:34 - INFO - __main__ -     precision = 0.7741935483870968\n",
      "10/31/2024 04:31:34 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:31:34 - INFO - __main__ -   start epoch 8\n",
      " 90%|████████████████████████████████████    | 918/1020 [09:51<01:01,  1.65it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.31it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.15it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.57it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.78it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.88it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.95it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.00it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.92it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:32:40 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:32:40 - INFO - __main__ -     accuracy = 0.8958904109589041\n",
      "10/31/2024 04:32:40 - INFO - __main__ -     f1 = 0.7164179104477612\n",
      "10/31/2024 04:32:40 - INFO - __main__ -     loss = 0.36226482405934646\n",
      "10/31/2024 04:32:40 - INFO - __main__ -     precision = 0.7868852459016393\n",
      "10/31/2024 04:32:40 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "10/31/2024 04:32:40 - INFO - __main__ -   start epoch 9\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:56<00:00,  1.69it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|███▊                                        | 2/23 [00:00<00:01, 18.30it/s]\u001b[A\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 20.11it/s]\u001b[A\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 20.57it/s]\u001b[A\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 20.78it/s]\u001b[A\n",
      " 61%|██████████████████████████▏                | 14/23 [00:00<00:00, 20.87it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 17/23 [00:00<00:00, 20.94it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 21.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:01<00:00, 20.93it/s]\u001b[A\n",
      "preds: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 04:33:45 - INFO - __main__ -   ***** Eval results *****\n",
      "10/31/2024 04:33:45 - INFO - __main__ -     accuracy = 0.8986301369863013\n",
      "10/31/2024 04:33:45 - INFO - __main__ -     f1 = 0.7218045112781954\n",
      "10/31/2024 04:33:45 - INFO - __main__ -     loss = 0.3797551128588131\n",
      "10/31/2024 04:33:45 - INFO - __main__ -     precision = 0.8\n",
      "10/31/2024 04:33:45 - INFO - __main__ -     recall = 0.6575342465753424\n",
      "100%|███████████████████████████████████████| 1020/1020 [10:57<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--tokenizer_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--do_train \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 2 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "10/31/2024 06:36:53 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "10/31/2024 06:36:53 - INFO - __main__ -   Training/evaluation parameters Namespace(id2doc_path='dataset/beir/processed/12_7/document.json', id2query_path='dataset/beir/processed/12_7/query.json', train_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/train.json', eval_query2doc_path='dataset/beir/processed_bm25/12_7/qrels/test.json', test_query2doc_path=None, source_block_size=512, target_block_size=128, local_rank=-1, output_dir='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2', do_train=False, do_eval=False, do_test=True, do_generate=False, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_device_generate_batch_size=16, total_batch_size=64, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=0.1, num_train_epochs=10, eval_freq=1, seed=2, data_seed=None, n_gpu=1, device='cuda', fp16=True, ignore_index=-100, data_size=100000000000000, train_num_negative_sample=1, test_num_negative_sample=4, negative_doc_cand_type='all', model_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2', config_name=None, tokenizer_name_or_path='./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2', label_smoothing=0.0, task_type='classification', num_labels=2)\n",
      "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2\n",
      "10/31/2024 06:36:59 - INFO - __main__ -   train batch size: 16,         gradient_accumulation_steps: 4\n",
      "10/31/2024 06:36:59 - INFO - __main__ -   train_dataset_size: 0, eval_dataset_size: 650\n",
      "10/31/2024 06:36:59 - INFO - __main__ -   total steps: 0, warmup_steps: 0\n",
      "/home/hoang/.conda/envs/pytorch310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "10/31/2024 06:36:59 - INFO - __main__ -   *** Test ***\n",
      "100%|███████████████████████████████████████████| 41/41 [00:02<00:00, 20.03it/s]\n",
      "preds: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "10/31/2024 06:37:01 - INFO - __main__ -   ***** Test results *****\n",
      "10/31/2024 06:37:01 - INFO - __main__ -     accuracy = 0.9046153846153846\n",
      "10/31/2024 06:37:01 - INFO - __main__ -     f1 = 0.7669172932330827\n",
      "10/31/2024 06:37:01 - INFO - __main__ -     loss = 0.26835376814166767\n",
      "10/31/2024 06:37:01 - INFO - __main__ -     precision = 0.75\n",
      "10/31/2024 06:37:01 - INFO - __main__ -     recall = 0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2 \\\n",
    "--tokenizer_name_or_path ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2 \\\n",
    "--do_test \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2 \\\n",
    "--num_train_epochs 10 --learning_rate 5e-5 --seed 2 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  3 14:47:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:86:00.0 Off |                  Off |\n",
      "| 30%   59C    P2             408W / 450W |  23432MiB / 24564MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:AF:00.0 Off |                  Off |\n",
      "|  0%   46C    P8              37W / 450W |  22670MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1358806      C   ...uc/.conda/envs/genre_env/bin/python      384MiB |\n",
      "|    0   N/A  N/A   1406818      C   python                                    23038MiB |\n",
      "|    1   N/A  N/A    493003      C   python3                                   22664MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/03/2024 16:21:58 - INFO - __main__ -   ***** Eval results *****\n",
      "11/03/2024 16:21:58 - INFO - __main__ -     accuracy = 0.915068493150685\n",
      "11/03/2024 16:21:58 - INFO - __main__ -     f1 = 0.7633587786259542\n",
      "11/03/2024 16:21:58 - INFO - __main__ -     loss = 0.4555688118967025\n",
      "11/03/2024 16:21:58 - INFO - __main__ -     precision = 0.8620689655172413\n",
      "11/03/2024 16:21:58 - INFO - __main__ -     recall = 0.684931506849315\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-large \\\n",
    "--tokenizer_name_or_path FacebookAI/xlm-roberta-large \\\n",
    "--do_train \\\n",
    "--task_type classification --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-large_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "--num_train_epochs 30 --learning_rate 5e-5 --seed 0 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "--model_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--tokenizer_name_or_path FacebookAI/xlm-roberta-base \\\n",
    "--do_train \\\n",
    "--task_type pairwise --negative_doc_cand_type all \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--train_query2doc_path dataset/beir/processed_bm25/12_7/qrels/train.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/dev.json \\\n",
    "--output_dir ./model/fine_tuned_models/xlm-roberta-base_12_7_pairwise_all_e30_ns1_lr5e-5_s0 \\\n",
    "--num_train_epochs 30 --learning_rate 5e-5 --seed 0 \\\n",
    "--per_device_train_batch_size 16 --per_device_eval_batch_size 16 \\\n",
    "--per_device_generate_batch_size 16 --total_batch_size 64 \\\n",
    "--source_block_size 512 --n_gpu 1 --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "100%|███████████████████████████████████████| 130/130 [00:00<00:00, 6091.40it/s]\n",
      "Search time:0.02431035041809082\n",
      "MRR@10: 0.3857\n",
      "MAP@10: 0.3234\n",
      "Recall@1: 0.2090\t\tMy_recall@1: 0.2615\n",
      "Recall@3: 0.3635\t\tMy_recall@3: 0.3731\n",
      "Recall@5: 0.4405\t\tMy_recall@5: 0.4447\n",
      "Recall@10: 0.5254\t\tMy_recall@10: 0.5259\n",
      "Recall@100: 0.8308\t\tMy_recall@100: 0.8308\n",
      "Recall@200: 0.8308\t\tMy_recall@200: 0.8308\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u evaluate.py \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--use_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 + Normal LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 130/130 [00:42<00:00,  3.05it/s]\n",
      "Search time:42.64936542510986\n",
      "MRR@10: 0.6007\n",
      "MAP@10: 0.5391\n",
      "Recall@1: 0.3674\t\tMy_recall@1: 0.5000\n",
      "Recall@3: 0.5797\t\tMy_recall@3: 0.5910\n",
      "Recall@5: 0.6509\t\tMy_recall@5: 0.6526\n",
      "Recall@10: 0.7561\t\tMy_recall@10: 0.7563\n",
      "Recall@100: 0.8308\t\tMy_recall@100: 0.8308\n",
      "Recall@200: 0.8308\t\tMy_recall@200: 0.8308\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u evaluate.py \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--batch_size 16 \\\n",
    "--bert_num_candidate 100 \\\n",
    "--source_block_size 512 \\\n",
    "--bert_task_type classification \\\n",
    "--use_bm25 --use_bert \\\n",
    "--model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 + Normal LM + Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "100%|█████████████████████████████████████████| 130/130 [00:55<00:00,  2.36it/s]\n",
      "Search time:55.067251205444336\n",
      "MRR@10: 0.6505\n",
      "MAP@10: 0.5892\n",
      "Recall@1: 0.4156\t\tMy_recall@1: 0.5538\n",
      "Recall@3: 0.6276\t\tMy_recall@3: 0.6397\n",
      "Recall@5: 0.7074\t\tMy_recall@5: 0.7091\n",
      "Recall@10: 0.7561\t\tMy_recall@10: 0.7563\n",
      "Recall@100: 0.8308\t\tMy_recall@100: 0.8308\n",
      "Recall@200: 0.8308\t\tMy_recall@200: 0.8308\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u evaluate.py \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--batch_size 16 \\\n",
    "--bert_num_candidate 100 --second_bert_num_candidate 10 \\\n",
    "--source_block_size 512 --second_source_block_size 512 \\\n",
    "--bert_task_type classification --second_bert_task_type classification \\\n",
    "--use_bm25 --use_bert --use_second_bert \\\n",
    "--model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--second_model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s0 \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 + Larger LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoang/multi-stage-reranking\n",
      "100%|█████████████████████████████████████████| 130/130 [03:29<00:00,  1.61s/it]\n",
      "Search time:209.9298689365387\n",
      "MRR@10: 0.7444\n",
      "MAP@10: 0.6861\n",
      "Recall@1: 0.5397\t\tMy_recall@1: 0.6923\n",
      "Recall@3: 0.7017\t\tMy_recall@3: 0.7167\n",
      "Recall@5: 0.7415\t\tMy_recall@5: 0.7432\n",
      "Recall@10: 0.7850\t\tMy_recall@10: 0.7854\n",
      "Recall@100: 0.8308\t\tMy_recall@100: 0.8308\n",
      "Recall@200: 0.8308\t\tMy_recall@200: 0.8308\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u evaluate.py \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--batch_size 16 \\\n",
    "--bert_num_candidate 100 \\\n",
    "--source_block_size 512 \\\n",
    "--bert_task_type classification \\\n",
    "--use_bm25 --use_bert \\\n",
    "--model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-large_12_7_classification_all_e10_ns1_lr5e-5_s0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 + Normal LM + Pairwise LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/hoang/multi-stage-reranking\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u evaluate.py \\\n",
    "--id2doc_path dataset/beir/processed/12_7/document.json \\\n",
    "--id2query_path dataset/beir/processed/12_7/query.json \\\n",
    "--eval_query2doc_path dataset/beir/processed_bm25/12_7/qrels/test.json \\\n",
    "--batch_size 16 \\\n",
    "--bert_num_candidate 100 --second_bert_num_candidate 10 \\\n",
    "--source_block_size 512 --second_source_block_size 512 \\\n",
    "--bert_task_type classification --second_bert_task_type pairwise \\\n",
    "--use_bm25 --use_bert --use_second_bert \\\n",
    "--model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_classification_all_e10_ns1_lr5e-5_s1 \\\n",
    "--second_model_name_or_path \\\n",
    "./model/fine_tuned_models/xlm-roberta-base_12_7_pairwise_all_e30_ns1_lr5e-5_s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
